from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import Dict, Any, List, Optional
import requests
import uuid
import json
import asyncio
import logging
from datetime import datetime, timedelta

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = FastAPI(title="N8N Clone API", version="1.0.0")

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # –í –ø—Ä–æ–¥–∞–∫—à–µ–Ω–µ —É–∫–∞–∑–∞—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –¥–æ–º–µ–Ω—ã
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# –•—Ä–∞–Ω–∏–ª–∏—â–µ –¥–ª—è –∞–∫—Ç–∏–≤–Ω—ã—Ö —Ç–∞–π–º–µ—Ä–æ–≤
active_timers = {}
# –î–æ–±–∞–≤—å—Ç–µ –≥–ª–æ–±–∞–ª—å–Ω—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è workflow –ø–æ—Å–ª–µ –¥—Ä—É–≥–∏—Ö –≥–ª–æ–±–∞–ª—å–Ω—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö (–ø—Ä–∏–º–µ—Ä–Ω–æ —Å—Ç—Ä–æ–∫–∞ 30)
saved_workflows = {}
# –î–æ–±–∞–≤—å—Ç–µ —ç—Ç—É –≥–ª–æ–±–∞–ª—å–Ω—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –Ω–æ–¥
node_execution_results = {}

# –ú–æ–¥–µ–ª–∏ –¥–∞–Ω–Ω—ã—Ö
class NodeConfig(BaseModel):
    authToken: Optional[str] = None
    systemMessage: Optional[str] = None
    userMessage: Optional[str] = None
    clearHistory: Optional[bool] = False
    to: Optional[str] = None
    subject: Optional[str] = None
    body: Optional[str] = None
    query: Optional[str] = None
    connection: Optional[str] = None
    url: Optional[str] = None
    method: Optional[str] = None
    headers: Optional[str] = None
    interval: Optional[int] = None
    timezone: Optional[str] = None

class Node(BaseModel):
    id: str
    type: str
    position: Dict[str, float]
    data: Dict[str, Any]

class Connection(BaseModel):
    id: str
    source: str
    target: str

class WorkflowExecuteRequest(BaseModel):
    nodes: List[Node]
    connections: List[Connection]
    startNodeId: Optional[str] = None

class ExecutionResult(BaseModel):
    success: bool
    result: Optional[Dict[str, Any]] = None
    error: Optional[str] = None
    logs: List[Dict[str, Any]] = []

# –î–æ–±–∞–≤—å—Ç–µ —ç—Ç—É –º–æ–¥–µ–ª—å –¥–∞–Ω–Ω—ã—Ö –ø–æ—Å–ª–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –º–æ–¥–µ–ª–µ–π (–ø—Ä–∏–º–µ—Ä–Ω–æ —Å—Ç—Ä–æ–∫–∞ 50-60)
class WorkflowSaveRequest(BaseModel):
    name: str
    nodes: List[Node]
    connections: List[Connection]

# GigaChat API –∫–ª–∞—Å—Å
class GigaChatAPI:
    def __init__(self):
        self.access_token = None
        self.conversation_history = []
        
    async def get_token(self, auth_token: str, scope: str = 'GIGACHAT_API_PERS') -> bool:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ç–æ–∫–µ–Ω–∞ –¥–æ—Å—Ç—É–ø–∞"""
        rq_uid = str(uuid.uuid4())
        url = "https://ngw.devices.sberbank.ru:9443/api/v2/oauth"
        headers = {
            'Content-Type': 'application/x-www-form-urlencoded',
            'Accept': 'application/json',
            'RqUID': rq_uid,
            'Authorization': f'Basic {auth_token}'
        }
        payload = {'scope': scope}

        try:
            # –í —Ä–µ–∞–ª—å–Ω–æ–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ aiohttp –¥–ª—è –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
            response = requests.post(url, headers=headers, data=payload, verify=False)
            if response.status_code == 200:
                self.access_token = response.json()['access_token']
                logger.info("‚úÖ GigaChat —Ç–æ–∫–µ–Ω –ø–æ–ª—É—á–µ–Ω —É—Å–ø–µ—à–Ω–æ")
                return True
            else:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Ç–æ–∫–µ–Ω–∞: {response.status_code}")
                return False
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Ç–æ–∫–µ–Ω–∞: {str(e)}")
            return False

    async def get_chat_completion(self, system_message: str, user_message: str) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ –æ—Ç GigaChat"""
        if not self.access_token:
            raise Exception("–¢–æ–∫–µ–Ω –¥–æ—Å—Ç—É–ø–∞ –Ω–µ –ø–æ–ª—É—á–µ–Ω")

        # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è
        messages = [{"role": "system", "content": system_message}]
        messages.extend(self.conversation_history)
        messages.append({"role": "user", "content": user_message})

        url = "https://gigachat.devices.sberbank.ru/api/v1/chat/completions"
        payload = {
            "model": "GigaChat",
            "messages": messages,
            "temperature": 1,
            "top_p": 0.1,
            "n": 1,
            "stream": False,
            "max_tokens": 512,
            "repetition_penalty": 1,
            "update_interval": 0
        }
        headers = {
            'Content-Type': 'application/json',
            'Accept': 'application/json',
            'Authorization': f'Bearer {self.access_token}'
        }

        try:
            response = requests.post(url, headers=headers, data=json.dumps(payload), verify=False)
            if response.status_code == 200:
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∏—Å—Ç–æ—Ä–∏—é
                self.conversation_history.append({"role": "user", "content": user_message})
                assistant_response = response.json()['choices'][0]['message']['content']
                self.conversation_history.append({"role": "assistant", "content": assistant_response})
                
                logger.info(f"‚úÖ –ü–æ–ª—É—á–µ–Ω –æ—Ç–≤–µ—Ç –æ—Ç GigaChat")
                logger.info(f"ü§ñ –û–¢–í–ï–¢: {assistant_response}")
                return {
                    "success": True,
                    "response": assistant_response,
                    "user_message": user_message,
                    "system_message": system_message,
                    "conversation_length": len(self.conversation_history)
                }
            else:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ API GigaChat: {response.status_code}")
                return {
                    "success": False,
                    "error": f"API Error: {response.status_code}",
                    "response": None
                }
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ GigaChat: {str(e)}")
            return {
                "success": False,
                "error": str(e),
                "response": None
            }

    def clear_history(self):
        """–û—á–∏—Å—Ç–∫–∞ –∏—Å—Ç–æ—Ä–∏–∏ –¥–∏–∞–ª–æ–≥–∞"""
        self.conversation_history = []
        logger.info("üóëÔ∏è –ò—Å—Ç–æ—Ä–∏—è –¥–∏–∞–ª–æ–≥–∞ –æ—á–∏—â–µ–Ω–∞")

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∏ –∑–∞–ø—É—Å–∫–∞ —Ç–∞–π–º–µ—Ä–∞
async def create_timer(timer_id: str, node_id: str, interval: int, workflow_info: Dict[str, Any]):
    """–°–æ–∑–¥–∞–µ—Ç –∏ –∑–∞–ø—É—Å–∫–∞–µ—Ç –Ω–æ–≤—ã–π —Ç–∞–π–º–µ—Ä"""
    # –û—Ç–º–µ–Ω—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π —Ç–∞–π–º–µ—Ä, –µ—Å–ª–∏ –æ–Ω –µ—Å—Ç—å
    if timer_id in active_timers and active_timers[timer_id]["task"] is not None:
        active_timers[timer_id]["task"].cancel()
        logger.info(f"üõë –û—Ç–º–µ–Ω–µ–Ω —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π —Ç–∞–π–º–µ—Ä {timer_id}")
    
    # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π —Ç–∞–π–º–µ—Ä
    next_execution = datetime.now() + timedelta(minutes=interval)
    
    # –°–æ–∑–¥–∞–µ–º –∏ –∑–∞–ø—É—Å–∫–∞–µ–º –∑–∞–¥–∞—á—É —Ç–∞–π–º–µ—Ä–∞
    task = asyncio.create_task(timer_task(timer_id, node_id, interval, workflow_info))
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç–∞–π–º–µ—Ä–µ
    active_timers[timer_id] = {
        "node_id": node_id,
        "interval": interval,
        "next_execution": next_execution,
        "task": task,
        "status": "active",
        "workflow": workflow_info
    }
    
    return {
        "id": timer_id,
        "node_id": node_id,
        "interval": interval,
        "next_execution": next_execution.isoformat(),
        "status": "active"
    }

async def update_timer(timer_id: str, interval: int):
    """–û–±–Ω–æ–≤–ª—è–µ—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π —Ç–∞–π–º–µ—Ä"""
    if timer_id not in active_timers:
        raise Exception(f"Timer {timer_id} not found")
    
    # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–º —Ç–∞–π–º–µ—Ä–µ
    timer_info = active_timers[timer_id]
    
    # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π —Ç–∞–π–º–µ—Ä —Å –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–º –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–º
    await create_timer(
        timer_id, 
        timer_info["node_id"], 
        interval, 
        timer_info["workflow"]
    )
    
    return {
        "id": timer_id,
        "node_id": timer_info["node_id"],
        "interval": interval,
        "next_execution": active_timers[timer_id]["next_execution"].isoformat(),
        "status": "active"
    }

async def timer_task(timer_id: str, node_id: str, interval: int, workflow_info: Dict[str, Any]):
    """–ó–∞–¥–∞—á–∞ —Ç–∞–π–º–µ—Ä–∞, –∫–æ—Ç–æ—Ä–∞—è –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ"""
    try:
        while True:
            # –ñ–¥–µ–º —É–∫–∞–∑–∞–Ω–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª
            logger.info(f"‚è∞ –ó–∞–ø—É—â–µ–Ω–∞ –∑–∞–¥–∞—á–∞ —Ç–∞–π–º–µ—Ä–∞ {timer_id} –¥–ª—è –Ω–æ–¥—ã {node_id} —Å –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–º {interval} –º–∏–Ω—É—Ç")
            logger.info(f"‚è∞ –¢–∞–π–º–µ—Ä {timer_id} –æ–∂–∏–¥–∞–µ—Ç {interval} –º–∏–Ω—É—Ç –¥–æ —Å–ª–µ–¥—É—é—â–µ–≥–æ –∑–∞–ø—É—Å–∫–∞")
            await asyncio.sleep(interval * 60)  # –ü–µ—Ä–µ–≤–æ–¥–∏–º –º–∏–Ω—É—Ç—ã –≤ —Å–µ–∫—É–Ω–¥—ã
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –≤—Ä–µ–º—è —Å–ª–µ–¥—É—é—â–µ–≥–æ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
            active_timers[timer_id]["next_execution"] = datetime.now() + timedelta(minutes=interval)
            
            # –í—ã–ø–æ–ª–Ω—è–µ–º workflow
            logger.info(f"üöÄ –¢–∞–π–º–µ—Ä {timer_id} –∑–∞–ø—É—Å–∫–∞–µ—Ç workflow")
            try:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç—É –∂–µ –ª–æ–≥–∏–∫—É, —á—Ç–æ –∏ execute_workflow
                workflow_request = WorkflowExecuteRequest(
                    nodes=workflow_info["nodes"],
                    connections=workflow_info["connections"],
                    startNodeId=node_id  # –ù–∞—á–∏–Ω–∞–µ–º —Å –Ω–æ–¥—ã —Ç–∞–π–º–µ—Ä–∞
                )
                
                # –í—ã–ø–æ–ª–Ω—è–µ–º workflow –ø—Ä–∞–≤–∏–ª—å–Ω–æ
                result = await execute_workflow_internal(workflow_request)
                
                if result.success:
                    logger.info(f"‚úÖ –¢–∞–π–º–µ—Ä {timer_id} —É—Å–ø–µ—à–Ω–æ –≤—ã–ø–æ–ª–Ω–∏–ª workflow")
                    
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ UI
                    if result.result:
                        for node_id_result, node_result in result.result.items():
                            node_execution_results[node_id_result] = {
                                "result": node_result,
                                "timestamp": datetime.now().isoformat(),
                                "status": "success"
                            }
                else:
                    logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è workflow —Ç–∞–π–º–µ—Ä–æ–º {timer_id}: {result.error}")
                    
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ workflow —Ç–∞–π–º–µ—Ä–æ–º {timer_id}: {str(e)}")
                import traceback
                logger.error(f"üîç –¢—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∞: {traceback.format_exc()}")
                
    except asyncio.CancelledError:
        logger.info(f"üõë –¢–∞–π–º–µ—Ä {timer_id} –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ –∑–∞–¥–∞—á–µ —Ç–∞–π–º–µ—Ä–∞ {timer_id}: {str(e)}")
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å —Ç–∞–π–º–µ—Ä–∞
        if timer_id in active_timers:
            active_timers[timer_id]["status"] = "error"




# –ò—Å–ø–æ–ª–Ω–∏—Ç–µ–ª–∏ –Ω–æ–¥
class NodeExecutors:
    def __init__(self):
        self.gigachat_api = GigaChatAPI()

    async def execute_gigachat(self, node: Node, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ GigaChat –Ω–æ–¥—ã"""
        logger.info(f"Executing GigaChat node: {node}")
        logger.info(f"Node data: {node.data}")
        logger.info(f"Config: {node.data.get('config', {})}")

        config = node.data.get('config', {})
        role = config.get('role', 'custom')  # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ–ª—É—á–µ–Ω–∏–µ —Ä–æ–ª–∏
        auth_token = config.get('authToken')
        system_message = config.get('systemMessage', '–¢—ã –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç')
        user_message = config.get('userMessage', '')
        clear_history = config.get('clearHistory', False)

        # –î–û–ë–ê–í–õ–Ø–ï–ú –õ–û–ì–ò–†–û–í–ê–ù–ò–ï –í–•–û–î–ù–´–• –î–ê–ù–ù–´–•
        logger.info(f"üì• –í—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –æ—Ç –ø—Ä–µ–¥—ã–¥—É—â–µ–π –Ω–æ–¥—ã: {json.dumps(input_data, ensure_ascii=False, indent=2)[:500]}...")

        logger.info(f"Auth token: {auth_token is not None}")
        logger.info(f"Role: {role}")  # –õ–æ–≥–∏—Ä—É–µ–º —Ä–æ–ª—å
        logger.info(f"User message: {user_message}")

        if not auth_token or not user_message:
            raise Exception("GigaChat: Auth token and user message are required")

        logger.info(f"ü§ñ –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ GigaChat –Ω–æ–¥—ã: {node.id}")
        logger.info(f"üìù –í–æ–ø—Ä–æ—Å: {user_message}")

        # –û—á–∏—â–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        if clear_history:
            self.gigachat_api.clear_history()

        # –ü–æ–ª—É—á–∞–µ–º —Ç–æ–∫–µ–Ω
        if not await self.gigachat_api.get_token(auth_token):
            raise Exception("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Ç–æ–∫–µ–Ω –¥–æ—Å—Ç—É–ø–∞")

        # –í—ã–ø–æ–ª–Ω—è–µ–º –∑–∞–ø—Ä–æ—Å
        result = await self.gigachat_api.get_chat_completion(system_message, user_message)
        
        if not result.get('success'):
            raise Exception(result.get('error', 'Unknown error'))

        # –§–æ—Ä–º–∏—Ä—É–µ–º –≤—ã—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Å–ª–µ–¥—É—é—â–∏—Ö –Ω–æ–¥
        return {
            **result,
            "output": {
                "text": result.get('response', ''),
                "question": user_message,
                "length": len(result.get('response', '')),
                "words": len(result.get('response', '').split()),
                "timestamp": datetime.now().isoformat()
            }
        }

    async def execute_email(self, node: Node, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ Email –Ω–æ–¥—ã"""
        config = node.data.get('config', {})
        to = config.get('to', '')
        subject = config.get('subject', '')
        body = config.get('body', '')

        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö –Ω–æ–¥ –µ—Å–ª–∏ –ø–æ–ª—è –ø—É—Å—Ç—ã–µ
        if not body and input_data and 'output' in input_data:
            body = input_data['output'].get('text', 'No content from previous node')
        
        if not subject and input_data and 'output' in input_data:
            subject = f"Response: {input_data['output'].get('question', 'Workflow Result')}"

        logger.info(f"üìß –û—Ç–ø—Ä–∞–≤–∫–∞ email –Ω–∞ {to}")
        logger.info(f"üìã –¢–µ–º–∞: {subject}")
        logger.info(f"üìÑ –¢–µ–ª–æ: {body[:100]}...")

        # –ó–¥–µ—Å—å –±—É–¥–µ—Ç —Ä–µ–∞–ª—å–Ω–∞—è –æ—Ç–ø—Ä–∞–≤–∫–∞ email (–Ω–∞–ø—Ä–∏–º–µ—Ä, —á–µ—Ä–µ–∑ SendGrid, SMTP)
        # –ü–æ–∫–∞ —Å–∏–º—É–ª–∏—Ä—É–µ–º
        await asyncio.sleep(1)

        return {
            "success": True,
            "sent": True,
            "to": to,
            "subject": subject,
            "body": body,
            "messageId": f"msg_{int(datetime.now().timestamp())}",
            "inputData": input_data
        }

    async def execute_database(self, node: Node, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ Database –Ω–æ–¥—ã"""
        config = node.data.get('config', {})
        query = config.get('query', '')
        connection = config.get('connection', 'postgres')

        # –ê–≤—Ç–æ–≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∑–∞–ø—Ä–æ—Å–∞ –µ—Å–ª–∏ –ø—É—Å—Ç–æ–π
        if not query and input_data and 'output' in input_data:
            text_data = input_data['output'].get('text', 'No data')[:100]
            query = f"INSERT INTO responses (text, timestamp) VALUES ('{text_data}', NOW())"

        logger.info(f"üóÑÔ∏è –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ SQL –∑–∞–ø—Ä–æ—Å–∞")
        logger.info(f"üîó –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ: {connection}")
        logger.info(f"üìù –ó–∞–ø—Ä–æ—Å: {query}")

        # –ó–¥–µ—Å—å –±—É–¥–µ—Ç —Ä–µ–∞–ª—å–Ω–æ–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ SQL –∑–∞–ø—Ä–æ—Å–∞
        # –ü–æ–∫–∞ —Å–∏–º—É–ª–∏—Ä—É–µ–º
        await asyncio.sleep(1)

        return {
            "success": True,
            "rows": [
                {
                    "id": 1,
                    "text": input_data.get('output', {}).get('text', 'Sample Data')[:100],
                    "created_at": datetime.now().isoformat()
                }
            ],
            "rowCount": 1,
            "query": query,
            "connection": connection,
            "inputData": input_data
        }

    async def execute_webhook(self, node: Node, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ Webhook –Ω–æ–¥—ã"""
        config = node.data.get('config', {})
        url = config.get('url', 'https://example.com/webhook')
        method = config.get('method', 'POST')
        headers = config.get('headers', 'Content-Type: application/json')

        logger.info(f"üåê Webhook –∑–∞–ø—Ä–æ—Å: {method} {url}")

        # –ó–¥–µ—Å—å –±—É–¥–µ—Ç —Ä–µ–∞–ª—å–Ω—ã–π HTTP –∑–∞–ø—Ä–æ—Å
        # –ü–æ–∫–∞ —Å–∏–º—É–ª–∏—Ä—É–µ–º
        await asyncio.sleep(1)

        return {
            "success": True,
            "message": "Webhook triggered",
            "url": url,
            "method": method,
            "timestamp": datetime.now().isoformat(),
            "inputData": input_data
        }

    async def execute_timer(self, node: Node, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ Timer –Ω–æ–¥—ã"""
        try:
            config = node.data.get('config', {})
            
            # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ç–µ—Ä–≤–∞–ª —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫
            try:
                interval = int(config.get('interval', 5))
            except ValueError:
                logger.warning(f"‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞: {config.get('interval')}. –ò—Å–ø–æ–ª—å–∑—É–µ–º –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 5")
                interval = 5
                
            timezone = config.get('timezone', 'UTC')

            logger.info(f"‚è∞ Timer –Ω–æ–¥–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∞: –∏–Ω—Ç–µ—Ä–≤–∞–ª {interval} –º–∏–Ω—É—Ç, —á–∞—Å–æ–≤–æ–π –ø–æ—è—Å {timezone}")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ —É–∂–µ —Ç–∞–π–º–µ—Ä –¥–ª—è —ç—Ç–æ–π –Ω–æ–¥—ã
            timer_id = f"timer_{node.id}"
            
            # –ü–æ–ª—É—á–∞–µ–º ID —Ç–µ–∫—É—â–µ–≥–æ workflow –∏–∑ –∏–º–µ–Ω–∏
            workflow_id = None
            for wf_id, wf_data in saved_workflows.items():
                if any(n.id == node.id for n in wf_data["nodes"]):
                    workflow_id = wf_id
                    break
            
            if not workflow_id:
                logger.warning(f"‚ö†Ô∏è Workflow –¥–ª—è –Ω–æ–¥—ã {node.id} –Ω–µ –Ω–∞–π–¥–µ–Ω. –¢–∞–π–º–µ—Ä –º–æ–∂–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ.")
            
            # –ï—Å–ª–∏ —ç—Ç–æ –ø–µ—Ä–≤–æ–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ, —Å–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π —Ç–∞–π–º–µ—Ä
            if timer_id not in active_timers:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–π workflow –∏–ª–∏ —Å–æ–∑–¥–∞–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π
                workflow_info = None
                if workflow_id and workflow_id in saved_workflows:
                    workflow_info = {
                        "nodes": saved_workflows[workflow_id]["nodes"],
                        "connections": saved_workflows[workflow_id]["connections"],
                        "startNodeId": node.id
                    }
                else:
                    # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π workflow —Å —Ç–µ–∫—É—â–µ–π –Ω–æ–¥–æ–π
                    workflow_info = {
                        "nodes": [node],
                        "connections": [],
                        "startNodeId": node.id
                    }
                
                # –°–æ–∑–¥–∞–µ–º —Ç–∞–π–º–µ—Ä
                await create_timer(timer_id, node.id, interval, workflow_info)
                
                logger.info(f"üïí –°–æ–∑–¥–∞–Ω –Ω–æ–≤—ã–π —Ç–∞–π–º–µ—Ä {timer_id} —Å –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–º {interval} –º–∏–Ω—É—Ç")
            else:
                # –û–±–Ω–æ–≤–ª—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π —Ç–∞–π–º–µ—Ä
                await update_timer(timer_id, interval)
                logger.info(f"üïí –û–±–Ω–æ–≤–ª–µ–Ω —Ç–∞–π–º–µ—Ä {timer_id} —Å –Ω–æ–≤—ã–º –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–º {interval} –º–∏–Ω—É—Ç")
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º –≤—ã—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Å–ª–µ–¥—É—é—â–∏—Ö –Ω–æ–¥
            current_time = datetime.now()
            next_execution = current_time + timedelta(minutes=interval)
            
            return {
                "success": True,
                "message": f"Timer triggered at {current_time.isoformat()}",
                "interval": interval,
                "timezone": timezone,
                "timestamp": current_time.isoformat(),
                "next_execution": next_execution.isoformat(),
                "timer_id": timer_id,
                "output": {
                    "text": f"Timer triggered at {current_time.isoformat()}. Next execution at {next_execution.isoformat()}",
                    "timestamp": current_time.isoformat(),
                    "interval": interval,
                    "timezone": timezone
                }
            }
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è Timer –Ω–æ–¥—ã: {str(e)}")
            raise Exception(f"Timer execution failed: {str(e)}")
    async def execute_join(self, node: Node, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ Join/Merge –Ω–æ–¥—ã"""
        config = node.data.get('config', {})
        wait_for_all = config.get('waitForAll', True)
        merge_strategy = config.get('mergeStrategy', 'combine_text')
        separator = config.get('separator', '\n\n---\n\n').replace('\\n', '\n')
        
        logger.info(f"üîÄ –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ Join/Merge –Ω–æ–¥—ã: {node.id}")
        logger.info(f"üì• –°—Ç—Ä–∞—Ç–µ–≥–∏—è: {merge_strategy}")
        
        # input_data –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å —Å–ª–æ–≤–∞—Ä—å inputs —Å –¥–∞–Ω–Ω—ã–º–∏ –æ—Ç –≤—Å–µ—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
        inputs = input_data.get('inputs', {})
        
        if not inputs:
            raise Exception("Join node requires input data from at least one source")
        
        logger.info(f"üìä –ü–æ–ª—É—á–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ –æ—Ç {len(inputs)} –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤: {list(inputs.keys())}")
        
        result = {}
        
        if merge_strategy == 'combine_text':
            # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ —Ç–µ–∫—Å—Ç—ã
            texts = []
            for i, (source_id, data) in enumerate(inputs.items()):
                # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –∏–∑ —Ä–∞–∑–Ω—ã—Ö –≤–æ–∑–º–æ–∂–Ω—ã—Ö –º–µ—Å—Ç
                text = ""
                if isinstance(data, dict):
                    if 'output' in data and 'text' in data['output']:
                        text = data['output']['text']
                    elif 'response' in data:
                        text = data['response']
                    elif 'text' in data:
                        text = data['text']
                    else:
                        # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ —Ç–µ–∫—Å—Ç, –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ —Å—Ç—Ä–æ–∫—É
                        text = json.dumps(data, ensure_ascii=False, indent=2)
                else:
                    text = str(data)
                
                texts.append(f"=== –ò—Å—Ç–æ—á–Ω–∏–∫ {i+1} ({source_id}) ===\n{text}")
            
            combined_text = separator.join(texts)
            
            result = {
                'output': {
                    'text': combined_text,
                    'source_count': len(inputs),
                    'sources': list(inputs.keys())
                },
                'success': True
            }
            
            logger.info(f"‚úÖ –û–±—ä–µ–¥–∏–Ω–µ–Ω–æ {len(texts)} —Ç–µ–∫—Å—Ç–æ–≤")
            
        elif merge_strategy == 'merge_json':
            # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ –¥–∞–Ω–Ω—ã–µ –≤ –µ–¥–∏–Ω—ã–π JSON
            merged_data = {
                'sources': {},
                'metadata': {
                    'source_count': len(inputs),
                    'merge_time': datetime.now().isoformat(),
                    'source_ids': list(inputs.keys())
                }
            }
            
            # –î–æ–±–∞–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –æ—Ç –∫–∞–∂–¥–æ–≥–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞
            for source_id, data in inputs.items():
                merged_data['sources'][source_id] = data
            
            result = {
                'output': {
                    'text': json.dumps(merged_data, ensure_ascii=False, indent=2),
                    'json': merged_data,
                    'source_count': len(inputs),
                    'sources': list(inputs.keys())
                },
                'success': True
            }
            
            logger.info(f"‚úÖ –û–±—ä–µ–¥–∏–Ω–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ –≤ JSON –æ—Ç {len(inputs)} –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤")
        
        else:
            raise Exception(f"Unknown merge strategy: {merge_strategy}")
        
        return result


# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª–µ–π
executors = NodeExecutors()

# API —ç–Ω–¥–ø–æ–∏–Ω—Ç—ã
@app.get("/")
async def root():
    return {"message": "N8N Clone API Server", "version": "1.0.0"}

@app.get("/health")
async def health_check():
    return {"status": "healthy", "timestamp": datetime.now().isoformat()}

@app.post("/execute-node")
async def execute_node(
    node_type: str,
    node_data: Dict[str, Any],
    input_data: Dict[str, Any] = None
):
    """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –æ—Ç–¥–µ–ª—å–Ω–æ–π –Ω–æ–¥—ã"""
    try:
        logger.info(f"Received request for node_type: {node_type}")
        logger.info(f"node_data: {json.dumps(node_data, indent=2)}")
        # –°–æ–∑–¥–∞–µ–º –æ–±—ä–µ–∫—Ç –Ω–æ–¥—ã
        node = Node(
            id=node_data.get('id', 'temp'),
            type=node_type,
            position=node_data.get('position', {'x': 0, 'y': 0}),
            data=node_data.get('data', {})
        )
        logger.info(f"Created node: {node}")
        logger.info(f"Node data: {node.data}")
        logger.info(f"Config: {node.data.get('config', {})}")

        # –í—ã–±–∏—Ä–∞–µ–º –∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å
        executor_map = {
            'gigachat': executors.execute_gigachat,
            'email': executors.execute_email,
            'database': executors.execute_database,
            'webhook': executors.execute_webhook,
            'timer': executors.execute_timer,
            'join': executors.execute_join  # –î–æ–±–∞–≤—å—Ç–µ —ç—Ç—É —Å—Ç—Ä–æ–∫—É
        }

        executor = executor_map.get(node_type)
        if not executor:
            raise HTTPException(status_code=400, detail=f"Unknown node type: {node_type}")

        # –í—ã–ø–æ–ª–Ω—è–µ–º –Ω–æ–¥—É
        result = await executor(node, input_data or {})
        
        return ExecutionResult(
            success=True,
            result=result,
            logs=[{
                "message": f"Node {node_type} executed successfully",
                "timestamp": datetime.now().isoformat(),
                "level": "info"
            }]
        )

    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –Ω–æ–¥—ã {node_type}: {str(e)}")
        return ExecutionResult(
            success=False,
            error=str(e),
            logs=[{
                "message": f"Error executing node {node_type}: {str(e)}",
                "timestamp": datetime.now().isoformat(),
                "level": "error"
            }]
        )
# –î–æ–±–∞–≤—å—Ç–µ —ç—Ç–æ—Ç —ç–Ω–¥–ø–æ–∏–Ω—Ç –ø–æ—Å–ª–µ –¥—Ä—É–≥–∏—Ö —ç–Ω–¥–ø–æ–∏–Ω—Ç–æ–≤ (–ø—Ä–∏–º–µ—Ä–Ω–æ —Å—Ç—Ä–æ–∫–∞ 600-650)
@app.post("/save-workflow")
async def save_workflow(request: WorkflowSaveRequest):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç workflow –Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ"""
    try:
        workflow_id = request.name.lower().replace(" ", "_")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º workflow –≤ –ø–∞–º—è—Ç–∏
        saved_workflows[workflow_id] = {
            "name": request.name,
            "nodes": request.nodes,
            "connections": request.connections,
            "updated_at": datetime.now().isoformat()
        }
        
        # –ú–æ–∂–Ω–æ —Ç–∞–∫–∂–µ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –Ω–∞ –¥–∏—Å–∫ –¥–ª—è –ø–µ—Ä—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏
        # with open(f"workflows/{workflow_id}.json", "w") as f:
        #     json.dump(saved_workflows[workflow_id], f)
        
        logger.info(f"‚úÖ Workflow '{request.name}' —Å–æ—Ö—Ä–∞–Ω–µ–Ω —É—Å–ø–µ—à–Ω–æ")
        
        return {
            "success": True,
            "workflow_id": workflow_id,
            "message": f"Workflow '{request.name}' saved successfully"
        }
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è workflow: {str(e)}")
        return {
            "success": False,
            "error": str(e)
        }

async def execute_workflow_internal(request: WorkflowExecuteRequest):
    """–í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è —Ñ—É–Ω–∫—Ü–∏—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è workflow (–±–µ–∑ HTTP –æ–±–µ—Ä—Ç–∫–∏)"""
    logs = []
    try:
        logger.info(f"üöÄ –ó–∞–ø—É—Å–∫ workflow —Å {len(request.nodes)} –Ω–æ–¥–∞–º–∏")
        
        # –î–µ—Ç–∞–ª—å–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–æ–¥ –∏ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π (–∏–∑ —Å—Ç–∞—Ä–æ–π –≤–µ—Ä—Å–∏–∏)
        for node in request.nodes:
            logger.info(f"üìã –ù–æ–¥–∞ {node.id} —Ç–∏–ø–∞ {node.type}: {node.data.get('label', '–ë–µ–∑ –º–µ—Ç–∫–∏')}")
        
        logger.info(f"üîó –°–æ–µ–¥–∏–Ω–µ–Ω–∏—è: {len(request.connections)}")
        for conn in request.connections:
            logger.info(f"üîó –°–æ–µ–¥–∏–Ω–µ–Ω–∏–µ: {conn.source} -> {conn.target}")
        
        # –•—Ä–∞–Ω–∏–ª–∏—â–µ –¥–ª—è –Ω–∞–∫–æ–ø–ª–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –¥–ª—è join –Ω–æ–¥
        join_node_data = {}
        
        # –ù–∞—Ö–æ–¥–∏–º —Å—Ç–∞—Ä—Ç–æ–≤—É—é –Ω–æ–¥—É
        start_node = None
        if request.startNodeId:
            start_node = next((n for n in request.nodes if n.id == request.startNodeId), None)
            logger.info(f"üéØ –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–∫–∞–∑–∞–Ω–Ω—É—é —Å—Ç–∞—Ä—Ç–æ–≤—É—é –Ω–æ–¥—É: {request.startNodeId}")
        else:
            # –ò—â–µ–º –Ω–æ–¥—É –±–µ–∑ –≤—Ö–æ–¥—è—â–∏—Ö —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π
            node_ids_with_inputs = {conn.target for conn in request.connections}
            startable_types = ['gigachat', 'webhook', 'timer']
            
            start_candidates = [
                n for n in request.nodes 
                if n.type in startable_types and n.id not in node_ids_with_inputs
            ]
            
            if start_candidates:
                start_node = start_candidates[0]
                logger.info(f"üîç –ù–∞–π–¥–µ–Ω–∞ —Å—Ç–∞—Ä—Ç–æ–≤–∞—è –Ω–æ–¥–∞ –±–µ–∑ –≤—Ö–æ–¥—è—â–∏—Ö —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π: {start_node.id}")
            else:
                # –ï—Å–ª–∏ –≤—Å–µ –Ω–æ–¥—ã –∏–º–µ—é—Ç –≤—Ö–æ–¥—è—â–∏–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è, –±–µ—Ä–µ–º –ª—é–±—É—é —Å—Ç–∞—Ä—Ç–æ–≤—É—é
                start_node = next((n for n in request.nodes if n.type in startable_types), None)
                logger.info(f"‚ö†Ô∏è –í—Å–µ –Ω–æ–¥—ã –∏–º–µ—é—Ç –≤—Ö–æ–¥—è—â–∏–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è, –±–µ—Ä–µ–º –ø–µ—Ä–≤—É—é –¥–æ—Å—Ç—É–ø–Ω—É—é: {start_node.id if start_node else 'None'}")

        if not start_node:
            raise Exception("No startable node found")

        # –ï—Å–ª–∏ —ç—Ç–æ –Ω–æ–¥–∞ Timer, –æ–±–Ω–æ–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ workflow –≤ —Ç–∞–π–º–µ—Ä–µ
        if start_node.type == "timer":
            timer_id = f"timer_{start_node.id}"
            if timer_id in active_timers:
                active_timers[timer_id]["workflow"] = {
                    "nodes": request.nodes,
                    "connections": request.connections,
                    "startNodeId": start_node.id
                }

        # –í—ã–ø–æ–ª–Ω—è–µ–º workflow
        results = {}
        
        
        async def execute_node_recursive(node_id: str, input_data: Dict[str, Any] = None, source_node_id: str = None):
            node = next((n for n in request.nodes if n.id == node_id), None)
            if not node:
                return None

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —ç—Ç–æ join –Ω–æ–¥–æ–π —Å –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–º–∏ –≤—Ö–æ–¥–∞–º–∏
            incoming_connections = [c for c in request.connections if c.target == node_id]
            
            if node.type == 'join' and len(incoming_connections) > 1:
                # –≠—Ç–æ join –Ω–æ–¥–∞ - –Ω–∞–∫–∞–ø–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ
                if node_id not in join_node_data:
                    join_node_data[node_id] = {
                        'expected_sources': set(c.source for c in incoming_connections),
                        'received_data': {}
                    }
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ –æ—Ç —Ç–µ–∫—É—â–µ–≥–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞
                if source_node_id:
                    join_node_data[node_id]['received_data'][source_node_id] = input_data
                    logger.info(f"üîÄ Join –Ω–æ–¥–∞ {node_id} –ø–æ–ª—É—á–∏–ª–∞ –¥–∞–Ω–Ω—ã–µ –æ—Ç {source_node_id}")
                    logger.info(f"üìä –û–∂–∏–¥–∞–µ—Ç—Å—è: {join_node_data[node_id]['expected_sources']}")
                    logger.info(f"üìä –ü–æ–ª—É—á–µ–Ω–æ –æ—Ç: {set(join_node_data[node_id]['received_data'].keys())}")
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –ø–æ–ª—É—á–∏–ª–∏ –ª–∏ –º—ã –¥–∞–Ω–Ω—ã–µ –æ—Ç –≤—Å–µ—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
                received_sources = set(join_node_data[node_id]['received_data'].keys())
                expected_sources = join_node_data[node_id]['expected_sources']
                
                if node.data.get('config', {}).get('waitForAll', True):
                    if received_sources != expected_sources:
                        # –ï—â–µ –Ω–µ –≤—Å–µ –¥–∞–Ω–Ω—ã–µ –ø–æ–ª—É—á–µ–Ω—ã
                        logger.info(f"‚è≥ Join –Ω–æ–¥–∞ {node_id} –∂–¥–µ—Ç –¥–∞–Ω–Ω—ã–µ –æ—Ç {expected_sources - received_sources}")
                        return None
                
                # –í—Å–µ –¥–∞–Ω–Ω—ã–µ –ø–æ–ª—É—á–µ–Ω—ã –∏–ª–∏ –Ω–µ –∂–¥–µ–º –≤—Å–µ—Ö - –≤—ã–ø–æ–ª–Ω—è–µ–º join
                input_data = {'inputs': join_node_data[node_id]['received_data']}
                
                # –û—á–∏—â–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
                del join_node_data[node_id]
            
            # –õ–æ–≥–∏—Ä—É–µ–º –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ
            logs.append({
                "message": f"Executing {node.data.get('label', node.type)}...",
                "timestamp": datetime.now().isoformat(),
                "level": "info",
                "nodeId": node_id
            })

            # –í—ã–ø–æ–ª–Ω—è–µ–º –Ω–æ–¥—É
            executor_map = {
                'gigachat': executors.execute_gigachat,
                'email': executors.execute_email,
                'database': executors.execute_database,
                'webhook': executors.execute_webhook,
                'timer': executors.execute_timer,
                'join': executors.execute_join
            }

            executor = executor_map.get(node.type)
            if executor:
                result = await executor(node, input_data or {})
                results[node_id] = result
                
                logs.append({
                    "message": f"{node.data.get('label', node.type)} completed successfully",
                    "timestamp": datetime.now().isoformat(),
                    "level": "success",
                    "nodeId": node_id
                })

                # –ù–∞—Ö–æ–¥–∏–º —Å–ª–µ–¥—É—é—â–∏–µ –Ω–æ–¥—ã
                next_connections = [c for c in request.connections if c.source == node_id]
                for connection in next_connections:
                    await execute_node_recursive(connection.target, result, node_id)

                return result
            else:
                raise Exception(f"Unknown node type: {node.type}")

        # –ó–∞–ø—É—Å–∫–∞–µ–º –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ
        await execute_node_recursive(start_node.id)

        return ExecutionResult(
            success=True,
            result=results,
            logs=logs
        )

    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è workflow: {str(e)}")
        return ExecutionResult(
            success=False,
            error=str(e),
            logs=logs + [{
                "message": f"Workflow execution failed: {str(e)}",
                "timestamp": datetime.now().isoformat(),
                "level": "error"
            }]
        )


@app.post("/execute-workflow")
async def execute_workflow(request: WorkflowExecuteRequest):
    return await execute_workflow_internal(request)

# –î–æ–±–∞–≤—å—Ç–µ –Ω–æ–≤—ã–π —ç–Ω–¥–ø–æ–∏–Ω—Ç –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç—É—Å–æ–≤ –Ω–æ–¥
@app.post("/node-status")
async def get_node_status(node_ids: List[str]):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –Ω–æ–¥"""
    results = {}
    
    for node_id in node_ids:
        if node_id in node_execution_results:
            # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∏ –ø—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ —É—Å—Ç–∞—Ä–µ–ª –ª–∏ –æ–Ω (–Ω–µ —Å—Ç–∞—Ä—à–µ 5 –º–∏–Ω—É—Ç)
            result_data = node_execution_results[node_id]
            timestamp = datetime.fromisoformat(result_data["timestamp"])
            
            if datetime.now() - timestamp < timedelta(minutes=5):
                results[node_id] = result_data
                
                # –û—á–∏—â–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø–æ—Å–ª–µ –æ—Ç–ø—Ä–∞–≤–∫–∏, —á—Ç–æ–±—ã –Ω–µ –æ—Ç–ø—Ä–∞–≤–ª—è—Ç—å –µ–≥–æ –ø–æ–≤—Ç–æ—Ä–Ω–æ
                # –ø—Ä–∏ —Å–ª–µ–¥—É—é—â–µ–º –∑–∞–ø—Ä–æ—Å–µ (—ç—Ç–æ –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—Ç–∏—Ç –ø–æ–≤—Ç–æ—Ä–Ω–æ–µ –ø–æ–¥—Å–≤–µ—á–∏–≤–∞–Ω–∏–µ –Ω–æ–¥—ã)
                del node_execution_results[node_id]
    
    return {"results": results}

# –ù–æ–≤—ã–µ —ç–Ω–¥–ø–æ–∏–Ω—Ç—ã –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Ç–∞–π–º–µ—Ä–∞–º–∏

@app.get("/timers")
async def get_timers():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –≤—Å–µ—Ö –∞–∫—Ç–∏–≤–Ω—ã—Ö —Ç–∞–π–º–µ—Ä–æ–≤"""
    timers = []
    for timer_id, timer in active_timers.items():
        timers.append({
            "id": timer_id,
            "node_id": timer["node_id"],
            "interval": timer["interval"],
            "next_execution": timer["next_execution"].isoformat(),
            "status": timer["status"]
        })
    return {"timers": timers}

@app.get("/timers/{timer_id}")
async def get_timer(timer_id: str):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–º —Ç–∞–π–º–µ—Ä–µ"""
    if timer_id not in active_timers:
        raise HTTPException(status_code=404, detail=f"Timer {timer_id} not found")
    
    timer = active_timers[timer_id]
    return {
        "id": timer_id,
        "node_id": timer["node_id"],
        "interval": timer["interval"],
        "next_execution": timer["next_execution"].isoformat(),
        "status": timer["status"]
    }

@app.post("/timers/{timer_id}/pause")
async def pause_timer(timer_id: str):
    """–ü—Ä–∏–æ—Å—Ç–∞–Ω–æ–≤–∫–∞ —Ç–∞–π–º–µ—Ä–∞"""
    if timer_id not in active_timers:
        raise HTTPException(status_code=404, detail=f"Timer {timer_id} not found")
    
    # –û—Ç–º–µ–Ω—è–µ–º –∑–∞–¥–∞—á—É —Ç–∞–π–º–µ—Ä–∞
    if active_timers[timer_id]["task"] is not None:
        active_timers[timer_id]["task"].cancel()
    
    # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å
    active_timers[timer_id]["status"] = "paused"
    
    logger.info(f"‚è∏Ô∏è –¢–∞–π–º–µ—Ä {timer_id} –ø—Ä–∏–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
    
    return {
        "id": timer_id,
        "status": "paused",
        "message": "Timer paused successfully"
    }

@app.post("/timers/{timer_id}/resume")
async def resume_timer(timer_id: str):
    """–í–æ–∑–æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Ç–∞–π–º–µ—Ä–∞"""
    if timer_id not in active_timers:
        raise HTTPException(status_code=404, detail=f"Timer {timer_id} not found")
    
    timer = active_timers[timer_id]
    
    # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é –∑–∞–¥–∞—á—É —Ç–∞–π–º–µ—Ä–∞
    task = asyncio.create_task(timer_task(
        timer_id, 
        timer["node_id"], 
        timer["interval"], 
        timer["workflow"]
    ))
    
    # –û–±–Ω–æ–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç–∞–π–º–µ—Ä–µ
    timer["task"] = task
    timer["status"] = "active"
    timer["next_execution"] = datetime.now() + timedelta(minutes=timer["interval"])
    
    logger.info(f"‚ñ∂Ô∏è –¢–∞–π–º–µ—Ä {timer_id} –≤–æ–∑–æ–±–Ω–æ–≤–ª–µ–Ω")
    
    return {
        "id": timer_id,
        "status": "active",
        "next_execution": timer["next_execution"].isoformat(),
        "message": "Timer resumed successfully"
    }

@app.delete("/timers/{timer_id}")
async def delete_timer(timer_id: str):
    """–£–¥–∞–ª–µ–Ω–∏–µ —Ç–∞–π–º–µ—Ä–∞"""
    if timer_id not in active_timers:
        raise HTTPException(status_code=404, detail=f"Timer {timer_id} not found")
    
    # –û—Ç–º–µ–Ω—è–µ–º –∑–∞–¥–∞—á—É —Ç–∞–π–º–µ—Ä–∞
    if active_timers[timer_id]["task"] is not None:
        active_timers[timer_id]["task"].cancel()
    
    # –£–¥–∞–ª—è–µ–º —Ç–∞–π–º–µ—Ä –∏–∑ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞
    del active_timers[timer_id]
    
    logger.info(f"üóëÔ∏è –¢–∞–π–º–µ—Ä {timer_id} —É–¥–∞–ª–µ–Ω")
    
    return {
        "message": f"Timer {timer_id} deleted successfully"
    }

@app.post("/timers/{timer_id}/update")
async def update_timer_endpoint(timer_id: str, interval: int):
    """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞ —Ç–∞–π–º–µ—Ä–∞"""
    if timer_id not in active_timers:
        raise HTTPException(status_code=404, detail=f"Timer {timer_id} not found")
    
    result = await update_timer(timer_id, interval)
    
    logger.info(f"üîÑ –¢–∞–π–º–µ—Ä {timer_id} –æ–±–Ω–æ–≤–ª–µ–Ω —Å –Ω–æ–≤—ã–º –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–º {interval} –º–∏–Ω—É—Ç")
    
    return result

@app.post("/timers/{timer_id}/execute-now")
async def execute_timer_now(timer_id: str):
    """–ù–µ–º–µ–¥–ª–µ–Ω–Ω–æ–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ —Ç–∞–π–º–µ—Ä–∞"""
    if timer_id not in active_timers:
        raise HTTPException(status_code=404, detail=f"Timer {timer_id} not found")
    
    timer = active_timers[timer_id]
    
    # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ workflow
    workflow_info = timer["workflow"]
    
    try:
        # –°–æ–∑–¥–∞–µ–º –∑–∞–ø—Ä–æ—Å –Ω–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ workflow
        workflow_request = WorkflowExecuteRequest(
            nodes=workflow_info["nodes"],
            connections=workflow_info["connections"],
            startNodeId=timer["node_id"]
        )
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º workflow
        result = await execute_workflow_internal(workflow_request)
        
        logger.info(f"‚úÖ –¢–∞–π–º–µ—Ä {timer_id} –≤—ã–ø–æ–ª–Ω–µ–Ω –Ω–µ–º–µ–¥–ª–µ–Ω–Ω–æ")
        
        return result
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –Ω–µ–º–µ–¥–ª–µ–Ω–Ω–æ–º –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ —Ç–∞–π–º–µ—Ä–∞ {timer_id}: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

# –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∑–∞–ø—É—Å–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞
@app.on_event("startup")
async def startup_event():
    """–í—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ —Å–µ—Ä–≤–µ—Ä–∞"""
    logger.info("üöÄ –°–µ—Ä–≤–µ—Ä –∑–∞–ø—É—â–µ–Ω")

# –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ —Å–µ—Ä–≤–µ—Ä–∞
@app.on_event("shutdown")
async def shutdown_event():
    """–í—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –ø—Ä–∏ –æ—Å—Ç–∞–Ω–æ–≤–∫–µ —Å–µ—Ä–≤–µ—Ä–∞"""
    logger.info("üõë –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –≤—Å–µ—Ö —Ç–∞–π–º–µ—Ä–æ–≤...")
    
    # –û—Ç–º–µ–Ω—è–µ–º –≤—Å–µ –∞–∫—Ç–∏–≤–Ω—ã–µ —Ç–∞–π–º–µ—Ä—ã
    for timer_id, timer in active_timers.items():
        if timer["task"] is not None:
            timer["task"].cancel()
    
    logger.info("üëã –°–µ—Ä–≤–µ—Ä –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")

if __name__ == "__main__":
    import uvicorn
    print("üöÄ –ó–∞–ø—É—Å–∫ FastAPI —Å–µ—Ä–≤–µ—Ä–∞...")
    print("üì° API –±—É–¥–µ—Ç –¥–æ—Å—Ç—É–ø–µ–Ω –Ω–∞: http://localhost:8000")
    print("üìö –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è: http://localhost:8000/docs")
    uvicorn.run(app, host="0.0.0.0", port=8000)

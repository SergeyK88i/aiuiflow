import logging
import json
from typing import Dict, Any

from scripts.models.schemas import Node, WorkflowExecuteRequest
from scripts.services.giga_chat import GigaChatAPI
from scripts.utils.template_engine import replace_templates
from scripts.services.storage import get_workflow_by_id

logger = logging.getLogger(__name__)

async def execute_dispatcher(node: Node, label_to_id_map: Dict[str, str], input_data: Dict[str, Any], gigachat_api: GigaChatAPI, sessions: Dict, all_results: Dict[str, Any]) -> Dict[str, Any]:
    """–í—ã–ø–æ–ª–Ω—è–µ—Ç –¥–∏—Å–ø–µ—Ç—á–µ—Ä –≤ —Ä–µ–∂–∏–º–µ router –∏–ª–∏ orchestrator"""
    config = node.data.get('config', {})
    dispatcher_type = config.get('dispatcher_type') or config.get('dispatcherType', 'router')

    logger.info(f"üéØ Executing dispatcher {node.id} in {dispatcher_type} mode")
    
    if dispatcher_type == 'router':
        return await execute_router_dispatcher(node, label_to_id_map, input_data, gigachat_api)
    
    elif dispatcher_type == 'orchestrator':
        return await execute_orchestrator_dispatcher(node, label_to_id_map, input_data, gigachat_api, sessions)
    
    else:
        raise Exception(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–∏–ø –¥–∏—Å–ø–µ—Ç—á–µ—Ä–∞: {dispatcher_type}")

async def execute_router_dispatcher(node: Node, label_to_id_map: Dict[str, str], input_data: Dict[str, Any], gigachat_api: GigaChatAPI) -> Dict[str, Any]:
    """–ê–≥–µ–Ω—Ç-–¥–∏—Å–ø–µ—Ç—á–µ—Ä, –∫–æ—Ç–æ—Ä—ã–π –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∑–∞–ø—Ä–æ—Å –∏ –≤—ã–±–∏—Ä–∞–µ—Ç –Ω—É–∂–Ω—ã–π workflow (—Å—Ç–∞—Ä–∞—è –ª–æ–≥–∏–∫–∞)"""
    logger.info(f"DEBUG: input_data for dispatcher: {json.dumps(input_data, ensure_ascii=False, indent=2)}")

    logger.info(f"üîÄ Executing Router Dispatcher node: {node.id}")
    config = node.data.get('config', {})
    
    query_template = config.get('userQueryTemplate') or '{{ input.output.text }}'

    if not label_to_id_map:
        label_to_id_map = {}
        for k, v in all_results.items():
            if isinstance(v, dict) and 'label' in v:
                label_to_id_map[v['label']] = k

    user_query = replace_templates(query_template, input_data, label_to_id_map, all_results).strip()

    if not user_query:
        raise Exception("Dispatcher: User query not found in input data.")

    workflow_routes = config.get('routes', {})
    if not workflow_routes:
        raise Exception("Dispatcher: Routes are not configured.")

    category = 'default'
    
    if config.get('useAI', True):
        auth_token = config.get('dispatcherAuthToken')
        if not auth_token:
            raise Exception("Dispatcher: GigaChat auth token is required for AI mode.")

        dispatcher_prompt = config.get('dispatcherPrompt')
        DEFAULT_PROMPT = (
            "–û–ø—Ä–µ–¥–µ–ª–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏—é –∑–∞–ø—Ä–æ—Å–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏ –≤—ã–±–µ—Ä–∏ –ø–æ–¥—Ö–æ–¥—è—â–∏–π –æ–±—Ä–∞–±–æ—Ç—á–∏–∫.\n"
            "–î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏: {–∫–∞—Ç–µ–≥–æ—Ä–∏–∏}\n"
            "–ó–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {–∑–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è}\n"
            "–û—Ç–≤–µ—Ç—å –¢–û–õ–¨–ö–û –æ–¥–Ω–∏–º —Å–ª–æ–≤–æ–º - –Ω–∞–∑–≤–∞–Ω–∏–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∏."
        )
        categories_desc = []
        for name, info in workflow_routes.items():
            desc = info.get("description", "")
            keywords = ", ".join(info.get("keywords", []))
            part = f"{name}"
            if desc:
                part += f" ‚Äî {desc}"
            if keywords:
                part += f" (–∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞: {keywords})"
            categories_desc.append(part)

        categories_str = "; ".join(categories_desc)
        prompt_template = dispatcher_prompt or DEFAULT_PROMPT
        classification_prompt = prompt_template.replace("{–∫–∞—Ç–µ–≥–æ—Ä–∏–∏}", categories_str).replace("{–∑–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è}", user_query)
        logger.info(f"AI classification prompt:\n{classification_prompt}")

        if await gigachat_api.get_token(auth_token):
            gigachat_result = await gigachat_api.get_chat_completion(
                "–¢—ã - –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –∑–∞–ø—Ä–æ—Å–æ–≤. –û—Ç–≤–µ—á–∞–π —Ç–æ–ª—å–∫–æ –æ–¥–Ω–∏–º —Å–ª–æ–≤–æ–º - –Ω–∞–∑–≤–∞–Ω–∏–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∏.",
                classification_prompt
            )
            response_text = gigachat_result.get('response', 'default').strip().lower()
            if response_text in workflow_routes:
                category = response_text
            else:
                logger.warning(f"GigaChat returned an unknown category '{response_text}', using default.")
        else:
            logger.error("Dispatcher: Failed to get GigaChat token.")

    else:
        query_lower = user_query.lower()
        for cat_name, cat_info in workflow_routes.items():
            if cat_name != 'default' and 'keywords' in cat_info:
                if any(keyword.lower() in query_lower for keyword in cat_info['keywords']):
                    category = cat_name
                    break
    
    selected_route = workflow_routes.get(category, workflow_routes.get('default'))
    if not selected_route:
        raise Exception(f"Dispatcher: No route found for category '{category}' and no default route is set.")

    workflow_id = selected_route['workflow_id']
    logger.info(f"üéØ –î–∏—Å–ø–µ—Ç—á–µ—Ä –≤—ã–±—Ä–∞–ª –∫–∞—Ç–µ–≥–æ—Ä–∏—é: {category} -> –ó–∞–ø—É—Å–∫ workflow: {workflow_id}")

    workflow_data = get_workflow_by_id(workflow_id)
    if not workflow_data:
        raise Exception(f"Dispatcher: Target workflow '{workflow_id}' not found.")

    from scripts.core.workflow_engine import execute_workflow_internal
    workflow_request = WorkflowExecuteRequest(
        nodes=workflow_data["nodes"],
        connections=workflow_data["connections"]
    )
    
    sub_workflow_result = await execute_workflow_internal(
        workflow_request, 
        initial_input_data={
            **input_data,
            "dispatcher_info": {
                "category": category,
                "original_query": user_query,
                "selected_workflow": workflow_id
            }
        }
    )

    return {
        **sub_workflow_result.result,
        "success": sub_workflow_result.success,
        "dispatcher_category": category,
        "executed_workflow_id": workflow_id,
        "output": {
            "text": f"–†–µ–∑—É–ª—å—Ç–∞—Ç –æ—Ç workflow '{workflow_id}': {sub_workflow_result.result}",
            "json": sub_workflow_result.result
        }
    }

async def execute_orchestrator_dispatcher(node: Node, label_to_id_map: Dict[str, str], input_data: Dict[str, Any], gigachat_api: GigaChatAPI, sessions: Dict):
    """–ü–ª–∞–Ω–∏—Ä—É—é—â–∏–π –¥–∏—Å–ø–µ—Ç—á–µ—Ä - —Å–æ–∑–¥–∞–µ—Ç –ø–ª–∞–Ω –∏ –∫–æ–æ—Ä–¥–∏–Ω–∏—Ä—É–µ—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ"""
    config = node.data.get('config', {})
    session_id = input_data.get('session_id')
    dispatcher_id = node.id
    
    logger.info(f"üéº Orchestrator dispatcher {dispatcher_id} processing request")
    
    if dispatcher_id not in sessions:
        sessions[dispatcher_id] = {}
    
    dispatcher_sessions = sessions[dispatcher_id]
    
    if input_data.get('return_to_dispatcher'):
        logger.info(f"üì• Handling workflow return for session {session_id}")
        return await handle_workflow_return(dispatcher_id, dispatcher_sessions, input_data)
    
    elif session_id and session_id in dispatcher_sessions:
        logger.info(f"üîÑ Continuing session {session_id}")
        return await handle_session_continuation(dispatcher_id, dispatcher_sessions, input_data)
    
    else:
        logger.info(f"üÜï Creating new session for new request")
        return await create_new_orchestrator_session(dispatcher_id, dispatcher_sessions, config, input_data, gigachat_api, label_to_id_map)

async def create_new_orchestrator_session(dispatcher_id: str, sessions: Dict, config: Dict, input_data: Dict[str, Any], gigachat_api: GigaChatAPI, label_to_id_map=None):
    """–°–æ–∑–¥–∞–µ—Ç –Ω–æ–≤—É—é —Å–µ—Å—Å–∏—é –∏ –ø–ª–∞–Ω –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è"""
    import uuid
    from datetime import datetime
    
    session_id = str(uuid.uuid4())
    
    query_template = config.get('userQueryTemplate') or '{{ input.query }}'

    if not label_to_id_map:
        label_to_id_map = {}
        for k, v in all_results.items():
            if isinstance(v, dict) and 'label' in v:
                label_to_id_map[v['label']] = k

    user_query = replace_templates(query_template, input_data, label_to_id_map, all_results).strip()

    if not user_query:
        user_query = (
            input_data.get('user_query')
            or input_data.get('message')
            or input_data.get('query')
            or input_data.get('text', '')
        )

    logger.info(f"üìã Creating execution plan for: {user_query}")

    plan = await create_execution_plan(config, user_query, gigachat_api)

    sessions[session_id] = {
        "plan": plan,
        "current_step": 0,
        "user_query": user_query,
        "accumulated_data": {},
        "created_at": datetime.now(),
        "dispatcher_id": dispatcher_id
    }
    
    logger.info(f"üíæ Session {session_id} created with {len(plan)} steps")
    
    if plan:
        first_step = plan[0]
        workflow_id = first_step.get('workflow_id')
        
        if workflow_id:
            workflow_input = {
                **input_data,
                "session_id": session_id,
                "dispatcher_context": {
                    "plan": plan,
                    "step": 0,
                    "dispatcher_id": dispatcher_id
                }
            }
            
            logger.info(f"üöÄ Launching first workflow: {workflow_id}")
            return await launch_workflow_by_id(workflow_id, workflow_input)
        else:
            raise Exception("–ü–µ—Ä–≤—ã–π —à–∞–≥ –ø–ª–∞–Ω–∞ –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç workflow_id")
    else:
        raise Exception("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –ø–ª–∞–Ω –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è")

async def create_execution_plan(config: Dict, user_query: str, gigachat_api: GigaChatAPI):
    """–°–æ–∑–¥–∞–µ—Ç –ø–ª–∞–Ω –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —á–µ—Ä–µ–∑ GigaChat"""
    import json
    
    available_workflows = (
        config.get('available_workflows')
        or config.get('availableWorkflows', {})
    )
    auth_token = config.get('dispatcherAuthToken', '')
    
    if not auth_token:
        raise Exception("–¢–æ–∫–µ–Ω –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏ –¥–ª—è –ø–ª–∞–Ω–∏—Ä—É—é—â–µ–≥–æ –¥–∏—Å–ø–µ—Ç—á–µ—Ä–∞ –Ω–µ —É–∫–∞–∑–∞–Ω")
    
    if not available_workflows:
        raise Exception("–î–æ—Å—Ç—É–ø–Ω—ã–µ workflow –¥–ª—è –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è –Ω–µ —É–∫–∞–∑–∞–Ω—ã")
    
    workflows_description = "\n".join([
        f"- {wf_id}: {wf_config.get('description', '–û–ø–∏—Å–∞–Ω–∏–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç')}"
        + (f" (–∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞: {', '.join(wf_config.get('keywords', []))})" if wf_config.get('keywords') else "")
        for wf_id, wf_config in available_workflows.items()
    ])

    
    planning_prompt = f"""
    –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø—Ä–æ—Å–∏—Ç: "{user_query}"    
    –î–æ—Å—Ç—É–ø–Ω—ã–µ workflow –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è:
    {workflows_description}
    
    –°–æ–∑–¥–∞–π –ø–æ—à–∞–≥–æ–≤—ã–π –ø–ª–∞–Ω –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON –º–∞—Å—Å–∏–≤–∞:
    [
        {{"workflow_id": "workflow1", "description": "—á—Ç–æ –¥–µ–ª–∞–µ—Ç —ç—Ç–æ—Ç —à–∞–≥"}},
        {{"workflow_id": "workflow2", "description": "—á—Ç–æ –¥–µ–ª–∞–µ—Ç —ç—Ç–æ—Ç —à–∞–≥"}}
    ]
    
    –ü—Ä–∞–≤–∏–ª–∞:
    1. –ò—Å–ø–æ–ª—å–∑—É–π —Ç–æ–ª—å–∫–æ workflow_id –∏–∑ —Å–ø–∏—Å–∫–∞ –≤—ã—à–µ
    2. –°–æ–∑–¥–∞–≤–∞–π –ª–æ–≥–∏—á–Ω—É—é –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å —à–∞–≥–æ–≤
    3. –û—Ç–≤–µ—á–∞–π –¢–û–õ–¨–ö–û JSON –º–∞—Å—Å–∏–≤–æ–º, –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
    4. –ï—Å–ª–∏ –∑–∞–¥–∞—á–∞ –ø—Ä–æ—Å—Ç–∞—è, –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –æ–¥–∏–Ω workflow
    """
    logger.info(f"Orchestrator planning prompt:\n{planning_prompt}")

    if await gigachat_api.get_token(auth_token):
        result = await gigachat_api.get_chat_completion(
            "–¢—ã –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫ –∑–∞–¥–∞—á. –ê–Ω–∞–ª–∏–∑–∏—Ä—É–π –∑–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏ —Å–æ–∑–¥–∞–≤–∞–π –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –ø–ª–∞–Ω –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∏–∑ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö workflow.",
            planning_prompt
        )
        
        try:
            plan = json.loads(result['response'])
            
            if not isinstance(plan, list):
                raise ValueError("–ü–ª–∞–Ω –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –º–∞—Å—Å–∏–≤–æ–º")
            
            for step in plan:
                if not isinstance(step, dict) or 'workflow_id' not in step:
                    raise ValueError("–ö–∞–∂–¥—ã–π —à–∞–≥ –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å workflow_id")
                
                if step['workflow_id'] not in available_workflows:
                    raise ValueError(f"Workflow {step['workflow_id']} –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö")
            
            logger.info(f"üìã –°–æ–∑–¥–∞–Ω –ø–ª–∞–Ω –∏–∑ {len(plan)} —à–∞–≥–æ–≤: {[s['workflow_id'] for s in plan]}")
            return plan
            
        except (json.JSONDecodeError, ValueError) as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –ø–ª–∞–Ω–∞: {result['response']}")
            logger.error(f"‚ùå –î–µ—Ç–∞–ª–∏ –æ—à–∏–±–∫–∏: {str(e)}")
            
            fallback_workflows = list(available_workflows.keys())
            if fallback_workflows:
                fallback_plan = [{"workflow_id": fallback_workflows[0], "description": "Fallback workflow"}]
                logger.info(f"üîÑ –ò—Å–ø–æ–ª—å–∑—É–µ–º fallback –ø–ª–∞–Ω: {fallback_plan}")
                return fallback_plan
            else:
                raise Exception("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –ø–ª–∞–Ω –∏ –Ω–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö workflow –¥–ª—è fallback")
    
    else:
        raise Exception("–ù–µ —É–¥–∞–ª–æ—Å—å –∞–≤—Ç–æ—Ä–∏–∑–æ–≤–∞—Ç—å—Å—è –≤ GigaChat API –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –ø–ª–∞–Ω–∞")

async def handle_workflow_return(dispatcher_id: str, sessions: Dict, input_data: Dict[str, Any]):
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –≤–æ–∑–≤—Ä–∞—Ç –æ—Ç workflow"""
    session_id = input_data.get('session_id')
    
    if not session_id or session_id not in sessions:
        raise Exception(f"–°–µ—Å—Å–∏—è {session_id} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ –¥–∏—Å–ø–µ—Ç—á–µ—Ä–µ {dispatcher_id}")
    
    session = sessions[session_id]
    
    workflow_result = input_data.get('workflow_result', {})
    completed_workflow = input_data.get('completed_workflow', 'unknown')
    
    logger.info(f"üì• Workflow {completed_workflow} –∑–∞–≤–µ—Ä—à–µ–Ω –¥–ª—è —Å–µ—Å—Å–∏–∏ {session_id}")
    
    session['accumulated_data'][f"step_{session['current_step']}_result"] = workflow_result
    session['accumulated_data'][f"step_{session['current_step']}_workflow"] = completed_workflow
    
    session['current_step'] += 1
    
    if session['current_step'] < len(session['plan']):
        next_step = session['plan'][session['current_step']]
        next_workflow_id = next_step.get('workflow_id')
        
        logger.info(f"‚û°Ô∏è –ü–µ—Ä–µ—Ö–æ–¥ –∫ —à–∞–≥—É {session['current_step']}: {next_workflow_id}")
        
        workflow_input = {
            "session_id": session_id,
            "user_query": session['user_query'],
            "previous_results": session['accumulated_data'],
            "dispatcher_context": {
                "plan": session['plan'],
                "step": session['current_step'],
                "dispatcher_id": dispatcher_id
            }
        }
        
        return await launch_workflow_by_id(next_workflow_id, workflow_input)
    
    else:
        logger.info(f"‚úÖ –ü–ª–∞–Ω –¥–ª—è —Å–µ—Å—Å–∏–∏ {session_id} –≤—ã–ø–æ–ª–Ω–µ–Ω –ø–æ–ª–Ω–æ—Å—Ç—å—é")
        
        final_result = {
            "success": True,
            "message": "–ü–ª–∞–Ω –≤—ã–ø–æ–ª–Ω–µ–Ω —É—Å–ø–µ—à–Ω–æ",
            "session_id": session_id,
            "completed_steps": len(session['plan']),
            "results": session['accumulated_data'],
            "session_completed": True,
            "output": {
                "text": f"–í—ã–ø–æ–ª–Ω–µ–Ω –ø–ª–∞–Ω –∏–∑ {len(session['plan'])} —à–∞–≥–æ–≤",
                "json": session['accumulated_data']
            }
        }
        
        del sessions[session_id]
        logger.info(f"üóëÔ∏è –°–µ—Å—Å–∏—è {session_id} —É–¥–∞–ª–µ–Ω–∞")
        
        return final_result

async def handle_session_continuation(dispatcher_id: str, sessions: Dict, input_data: Dict[str, Any]):
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π —Å–µ—Å—Å–∏–∏ (–Ω–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è)"""
    session_id = input_data.get('session_id')
    session = sessions[session_id]
    
    user_query = input_data.get('user_query', input_data.get('message', ''))
    
    logger.info(f"üîÑ –ü—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ —Å–µ—Å—Å–∏–∏ {session_id}: {user_query}")
    
    if 'additional_requests' not in session:
        session['additional_requests'] = []
    
    session['additional_requests'].append({
        "query": user_query,
        "timestamp": datetime.now().isoformat()
    })
    
    current_step = session['current_step']
    total_steps = len(session['plan'])
    
    return {
        "success": True,
        "message": f"–ó–∞–ø—Ä–æ—Å –¥–æ–±–∞–≤–ª–µ–Ω –∫ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π —Å–µ—Å—Å–∏–∏. –í—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è —à–∞–≥ {current_step + 1} –∏–∑ {total_steps}",
        "session_id": session_id,
        "current_step": current_step,
        "total_steps": total_steps,
        "additional_request_added": True,
        "output": {
            "text": f"–í–∞—à –∑–∞–ø—Ä–æ—Å –ø—Ä–∏–Ω—è—Ç. –°–µ–π—á–∞—Å –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è —à–∞–≥ {current_step + 1} –∏–∑ {total_steps}",
            "json": {
                "session_status": "active",
                "progress": f"{current_step}/{total_steps}"
            }
        }
    }

async def launch_workflow_by_id(workflow_id: str, input_data: Dict[str, Any]):
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç workflow –ø–æ ID"""
    workflow_data = get_workflow_by_id(workflow_id)
    if not workflow_data:
        raise Exception(f"Workflow {workflow_id} –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö workflow")
    
    logger.info(f"üöÄ –ó–∞–ø—É—Å–∫ workflow {workflow_id}")
    
    from scripts.core.workflow_engine import execute_workflow_internal
    workflow_request = WorkflowExecuteRequest(
        nodes=workflow_data["nodes"],
        connections=workflow_data["connections"]
    )
    
    result = await execute_workflow_internal(workflow_request, initial_input_data=input_data)
    
    return {
        "success": result.success,
        "workflow_id": workflow_id,
        "result": result.result,
        "error": result.error,
        "logs": result.logs,
        "output": {
            "text": f"Workflow {workflow_id} {'–≤—ã–ø–æ–ª–Ω–µ–Ω —É—Å–ø–µ—à–Ω–æ' if result.success else '–∑–∞–≤–µ—Ä—à–∏–ª—Å—è —Å –æ—à–∏–±–∫–æ–π'}",
            "json": result.result
        }
    }

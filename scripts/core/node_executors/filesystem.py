import logging
import json
from typing import Dict, Any

from scripts.models.schemas import Node
from scripts.services.storage import add_workflow # <--- –ü–ï–†–ï–ò–°–ü–û–õ–¨–ó–£–ï–ú –ö–û–î!
 
logger = logging.getLogger(__name__)
 
async def execute_filesystem(node: Node, input_data: Dict[str, Any], **kwargs) -> Dict[str, Any]:
    """
    –í—ã–ø–æ–ª–Ω—è–µ—Ç –æ–ø–µ—Ä–∞—Ü–∏–∏ —Å —Ñ–∞–π–ª–æ–≤–æ–π —Å–∏—Å—Ç–µ–º–æ–π, –≤ —á–∞—Å—Ç–Ω–æ—Å—Ç–∏, –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –≤–æ—Ä–∫—Ñ–ª–æ—É.
    """
    config = node.data.get('config', {})
    operation = config.get('fs_operation', 'update_workflows')
    logger.info(f"üíæ Executing File System node in '{operation}' mode.")

    if operation == 'update_workflows':
        # –û–∂–∏–¥–∞–µ–º, —á—Ç–æ –ø—Ä–µ–¥—ã–¥—É—â–∞—è –Ω–æ–¥–∞ (LLM) –≤–µ—Ä–Ω—É–ª–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ –ø–æ–ª–µ 'json'
        new_workflows = input_data.get('json', {})
 
        if not isinstance(new_workflows, dict):
            raise Exception("File System node (update_workflows) expects a dictionary of workflows as input.") 
        for workflow_id, workflow_data in new_workflows.items():
            logger.info(f"‚ûï Adding/updating workflow: {workflow_id}")
            # –í—ã–∑—ã–≤–∞–µ–º –Ω–∞—à—É —Ü–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é, –∫–æ—Ç–æ—Ä–∞—è —Å–∞–º–∞ –≤—Å–µ —Å–æ—Ö—Ä–∞–Ω–∏—Ç
            add_workflow(workflow_id, workflow_data)

        return {
            "success": True,
            "message": f"Successfully processed {len(new_workflows)} workflows.",
            "processed_ids": list(new_workflows.keys())
        }
    else:
        raise Exception(f"File System node: Unsupported operation '{operation}'.")
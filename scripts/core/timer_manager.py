import asyncio
import logging
import json
from datetime import datetime, timedelta
from typing import Dict, Any

from scripts.models.schemas import WorkflowExecuteRequest
from scripts.services.storage import get_workflow_by_id

logger = logging.getLogger(__name__)

active_timers: Dict[str, Dict[str, Any]] = {}

async def create_timer(timer_id: str, node_id: str, interval: int, workflow_info: Dict[str, Any]):
    """–°–æ–∑–¥–∞–µ—Ç –∏ –∑–∞–ø—É—Å–∫–∞–µ—Ç –Ω–æ–≤—ã–π —Ç–∞–π–º–µ—Ä"""
    if timer_id in active_timers and active_timers[timer_id]["task"] is not None:
        active_timers[timer_id]["task"].cancel()
        logger.info(f"üõë –û—Ç–º–µ–Ω–µ–Ω —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π —Ç–∞–π–º–µ—Ä {timer_id} –¥–ª—è –ø–µ—Ä–µ—Å–æ–∑–¥–∞–Ω–∏—è")

    task = asyncio.create_task(timer_task(timer_id, node_id, interval, workflow_info))

    active_timers[timer_id] = {
        "node_id": node_id,
        "interval": interval,
        "next_execution": datetime.now() + timedelta(minutes=int(interval)),
        "task": task,
        "status": "active",
        "workflow": workflow_info
    }
    logger.info(f"üïí –°–æ–∑–¥–∞–Ω/–ø–µ—Ä–µ—Å–æ–∑–¥–∞–Ω —Ç–∞–π–º–µ—Ä {timer_id} –¥–ª—è workflow '{workflow_info.get('workflow_id')}'")
    return active_timers[timer_id]

async def update_timer(timer_id: str, interval: int, workflow_info: Dict[str, Any]):
    """
    –û–±–Ω–æ–≤–ª—è–µ—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π —Ç–∞–π–º–µ—Ä.
    """
    if timer_id not in active_timers:
        raise Exception(f"Timer {timer_id} not found")

    timer_info = active_timers[timer_id]
    
    await create_timer(
        timer_id,
        timer_info["node_id"],
        interval,
        workflow_info
    )
    logger.info(f"üîÑ –û–±–Ω–æ–≤–ª–µ–Ω —Ç–∞–π–º–µ—Ä {timer_id} —Å –Ω–æ–≤—ã–º –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–º {interval} –º–∏–Ω—É—Ç")
    return active_timers[timer_id]

async def timer_task(timer_id: str, node_id: str, interval: int, workflow_info: Dict[str, Any]):
    """
    –ó–∞–¥–∞—á–∞ —Ç–∞–π–º–µ—Ä–∞, –∫–æ—Ç–æ—Ä–∞—è –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ.
    """
    try:
        while True:
            logger.info(f"‚è∞ –ó–∞–ø—É—â–µ–Ω–∞ –∑–∞–¥–∞—á–∞ —Ç–∞–π–º–µ—Ä–∞ {timer_id} –¥–ª—è –Ω–æ–¥—ã {node_id} —Å –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–º {interval} –º–∏–Ω—É—Ç")
            logger.info(f"‚è∞ –¢–∞–π–º–µ—Ä {timer_id} –æ–∂–∏–¥–∞–µ—Ç {interval} –º–∏–Ω—É—Ç –¥–æ —Å–ª–µ–¥—É—é—â–µ–≥–æ –∑–∞–ø—É—Å–∫–∞")
            await asyncio.sleep(int(interval) * 60)

            active_timers[timer_id]["next_execution"] = datetime.now() + timedelta(minutes=int(interval))
            active_timers[timer_id]["is_executing_workflow"] = True

            try:
                workflow_id = workflow_info.get("workflow_id")
                workflow_exists = await get_workflow_by_id(workflow_id)
                if not workflow_id or not workflow_exists:
                    logger.error(f"‚ùå Workflow —Å ID '{workflow_id}' –Ω–µ –Ω–∞–π–¥–µ–Ω. –¢–∞–π–º–µ—Ä {timer_id} –Ω–µ –º–æ–∂–µ—Ç –∑–∞–ø—É—Å—Ç–∏—Ç—å –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ.")
                    continue

                logger.info(f"üöÄ –¢–∞–π–º–µ—Ä {timer_id} –∑–∞–ø—É—Å–∫–∞–µ—Ç workflow '{workflow_id}'")

                workflow_data_raw = await get_workflow_by_id(workflow_id)
                workflow_data = dict(workflow_data_raw)
                nodes = json.loads(workflow_data.get('nodes', '[]'))
                connections = json.loads(workflow_data.get('connections', '[]'))

                from scripts.core.workflow_engine import execute_workflow_internal
                workflow_request = WorkflowExecuteRequest(
                    nodes=nodes,
                    connections=connections,
                    startNodeId=node_id
                )

                start_time = datetime.now()
                result = await execute_workflow_internal(workflow_request)
                execution_time = (datetime.now() - start_time).total_seconds()

                if result.success:
                    logger.info(f"‚úÖ Workflow '{workflow_id}' –≤—ã–ø–æ–ª–Ω–µ–Ω –∑–∞ {execution_time:.2f} —Å–µ–∫—É–Ω–¥")
                else:
                    logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è workflow '{workflow_id}' —Ç–∞–π–º–µ—Ä–æ–º {timer_id}: {result.error}")

            except Exception as e:
                logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ workflow —Ç–∞–π–º–µ—Ä–æ–º {timer_id}: {str(e)}")
                import traceback
                logger.error(f"üîç –¢—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∞: {traceback.format_exc()}")
            finally:
                if timer_id in active_timers:
                    active_timers[timer_id]["is_executing_workflow"] = False
                    logger.info(f"üîì –§–ª–∞–≥ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —Å–Ω—è—Ç –¥–ª—è —Ç–∞–π–º–µ—Ä–∞ {timer_id}")

    except asyncio.CancelledError:
        logger.info(f"üõë –¢–∞–π–º–µ—Ä {timer_id} –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
    except Exception as e:
        logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ –∑–∞–¥–∞—á–µ —Ç–∞–π–º–µ—Ä–∞ {timer_id}: {str(e)}")
        if timer_id in active_timers:
            active_timers[timer_id]["status"] = "error"

def get_timer_by_id(timer_id: str):
    return active_timers.get(timer_id)

def delete_timer_by_id(timer_id: str):
    if timer_id in active_timers:
        active_timers[timer_id]["task"].cancel()
        del active_timers[timer_id]

async def execute_timer_now_by_id(timer_id: str):
    timer = get_timer_by_id(timer_id)
    if not timer:
        raise Exception(f"Timer {timer_id} not found")

    workflow_id = timer['workflow']['workflow_id']
    node_id = timer['node_id']
    workflow_data_raw = await get_workflow_by_id(workflow_id)

    if not workflow_data_raw:
        raise Exception(f"Workflow {workflow_id} not found")

    workflow_data = dict(workflow_data_raw)
    nodes = json.loads(workflow_data.get('nodes', '[]'))
    connections = json.loads(workflow_data.get('connections', '[]'))

    from scripts.core.workflow_engine import execute_workflow_internal
    workflow_request = WorkflowExecuteRequest(
        nodes=nodes,
        connections=connections,
        startNodeId=node_id
    )
    return await execute_workflow_internal(workflow_request)